{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bd828e5",
   "metadata": {},
   "source": [
    "#### 1\t– Crie um modelo de classificação de imagens, a partir da importação da base de dados do Sci-kit Learn. Este modelo deve ter as seguintes características:\n",
    "- 1.1\tUtilize a base de dados Mnist Dataset;\n",
    "- 1.2\tDivida a base de treinamento e teste em 80/20;\n",
    "- 1.3\tUtilize a técnica de Cross Validation (K-fold = 5);\n",
    "- 1.4\tUtilize a técnica de Random Search ou Grid Search para escolha dos melhores parâmetros\n",
    "- 1.5\tFaça a impressão da matriz de confusão para o modelo\n",
    "\n",
    "\n",
    "Obs: Fique a vontade para usar outras bibliotecas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084f5a80",
   "metadata": {},
   "source": [
    "**3)** A base de dados está pronta, então vamos utilizar agora o algoritmo SVM para treinar o modelo. Para isso, observe o código a seguir e faça as devidas modificações. Em seguida observe a acurácia deste modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08836e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "\n",
    "#Criando um modelo SVM variando os parâmetros C e gamma\n",
    "model=SVC(C=0.99, gamma=0.0000001)\n",
    "\n",
    "#Treinando o modelo. Use aqui suas observações de treino e os targets de treino\n",
    "model.fit(Xtreino, Ytreino)\n",
    "\n",
    "#Fazendo predições. Use aqui sua base de teste\n",
    "result = model.predict(Xteste)\n",
    "\n",
    "#mostrando os resultados preditos pelo modelo \n",
    "print('Resultado:')\n",
    "print(result)\n",
    "\n",
    "print('Resultado Esperado:')\n",
    "#Os resultados esperados são os targets de teste, mostre-os a seguir\n",
    "print(Yteste)\n",
    "\n",
    "\n",
    "#agora vamos calcular a acurária do modelo usando a base de testes\n",
    "print(\"Acurácia:\", metrics.accuracy_score(result,Yteste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ddcd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(Xval)\n",
    "\n",
    "#mostrando os resultados preditos pelo modelo \n",
    "print('Resultado:')\n",
    "print(result)\n",
    "\n",
    "print('Resultado Esperado:')\n",
    "#Os resultados esperados são os targets de teste, mostre-os a seguir\n",
    "print(Yval)\n",
    "\n",
    "\n",
    "#agora vamos calcular a acurária do modelo usando a base de testes\n",
    "print(\"Acurácia:\", metrics.accuracy_score(result,Yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "229a0a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f2b7644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega a base de dados Mnist Dataset do Sci-kit Learn\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# Define as variáveis X e y\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ff227ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide a base de treinamento e teste em 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define os parâmetros a serem testados\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 500, num = 10)]\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8b54bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o número de folds do K-fold\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define o modelo de classificação\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Define o grid de parâmetros a ser testado\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2a6eb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "# Define a técnica de Random Search para escolha dos melhores parâmetros\n",
    "rf_random = RandomizedSearchCV(estimator = model, param_distributions = random_grid, n_iter = 100,\n",
    "                               cv = kfold, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Treina o modelo\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# Realiza a predição com o modelo\n",
    "y_pred = rf_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d624697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 28  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 33  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 33  0  1  0  0  0  0]\n",
      " [ 0  0  0  0 46  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 46  1  0  0  0]\n",
      " [ 0  0  0  0  0  1 34  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 33  0  1]\n",
      " [ 0  1  0  0  0  0  0  0 29  0]\n",
      " [ 0  0  0  0  0  0  0  1  0 39]]\n"
     ]
    }
   ],
   "source": [
    "# Imprime a matriz de confusão\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd1bcc6",
   "metadata": {},
   "source": [
    "#### 2. Após a etapa de treinamento, analise o modelo respondendo as questões a seguir:\n",
    "- 2.1 Qual a acurácia do modelo? Justifique\n",
    "- 2.2 O modelo teve uma boa performance? Justifique\n",
    "- 2.3 Quais foram os melhores parâmetros escolhidos? Justifique\n",
    "- 2.4 Quais as principais dificuldades encontradas para a criação do seu modelo de classificação?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da21819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisando o modelo\n",
    "# a) Qual a acurácia do modelo? Justifique.\n",
    "accuracy = rf_random.score(X_test, y_test)\n",
    "print('Acurácia do modelo:', accuracy)\n",
    "# A acurácia do modelo foi de 0.975, o que significa que ele acerta 97.5% das vezes nas predições. Isso demonstra \n",
    "# que o modelo possui uma boa capacidade de generalização.\n",
    "\n",
    "# b) O modelo teve uma boa performance? Justifique.\n",
    "Sim, o modelo teve uma boa performance. Como ele acertou 97.5% das vezes, isso indica que ele conseguiu estabelecer \n",
    "padrões na base de treinamento e aplicá-los de forma eficiente nos dados de teste. Além disso, a matriz de confusão \n",
    "revela que o modelo teve uma perfomance razoavelmente uniforme para todas as classes.\n",
    "\n",
    "# c) Quais foram os melhores parâmetros escolhidos? Justifique.\n",
    "O Random Search selecionou os seguintes parâmetros como sendo os melhores para este modelo:\n",
    "{'n_estimators': 300,\n",
    " 'min_samples_split': 2,\n",
    " 'min_samples_leaf': 1,\n",
    " 'max_depth': 80,\n",
    " 'bootstrap': False}\n",
    "Através desses parâmetros, é possível balancear a complexidade do modelo com a sua capacidade de generalização, \n",
    "evitando overfitting ou underfitting.\n",
    "\n",
    "# d) Quais as principais dificuldades encontradas para a criação do seu modelo de classificação?\n",
    "As principais dificuldades encontradas para a criação do modelo de classificação foram relacionadas à escolha dos \n",
    "parâmetros a serem utilizados, principalmente em relação à complexidade do modelo e ao seu equilíbrio entre \n",
    "precisão e generalização. Além disso, foi necessário entender a estrutura da base de dados para aplicar as técnicas \n",
    "de separação em treinamento e teste, validação cruzada e matriz de confusão.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132ed51c",
   "metadata": {},
   "source": [
    "#### 3. Faça uma pesquisa para conhecer um pouco mais sobre o universo de Machine Learning e responda as questões a seguir:\n",
    "- 3.1 Qual é a diferença entre um parâmetro de modelo e um algoritmo de aprendizagem de hiperparâmetro?\n",
    "- 3.2 Você pode citar quatro dos principais desafios do aprendizado de máquina?\n",
    "- 3.3 Se o seu modelo tem um ótimo desempenho nos dados de treinamento, mas generaliza mal para novas instâncias, o que está acontecendo? Você pode citar três soluções possíveis?\n",
    "- 3.4 O que é um conjunto de teste e por que você  deveria usa-lo?\n",
    "- 3.5 Qual é o propósito de um conjunto de validação?\n",
    "- 3.6 O que pode dar errado se você ajustar hiperparâmetro usando o conjunto de teste?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd1dcea",
   "metadata": {},
   "source": [
    "#### Respostas:\n",
    "3.1 Um parâmetro de modelo é uma configuração interna do modelo que é aprendida durante o treinamento, como os pesos em uma rede neural, enquanto um hiperparâmetro é uma configuração externa ao modelo, como a taxa de aprendizagem ou o número de camadas em uma rede neural.\n",
    "\n",
    "3.2 Quatro dos principais desafios do aprendizado de máquina são: lidar com dados incompletos, lidar com dados desbalanceados, evitar o sobreajuste (overfitting) e escolher o algoritmo de aprendizado correto.\n",
    "\n",
    "3.3 Se um modelo tem um ótimo desempenho nos dados de treinamento, mas generaliza mal para novas instâncias, isso significa que o modelo está sobreajustando os dados de treinamento e não consegue generalizar para novos dados. Algumas soluções possíveis são: aumentar a quantidade de dados de treinamento, reduzir a complexidade do modelo e usar regularização.\n",
    "\n",
    "3.4 Um conjunto de teste é um conjunto de dados separado do conjunto de treinamento que é usado para avaliar o desempenho do modelo após o treinamento. É importante usar um conjunto de teste para avaliar se o modelo está generalizando bem para novos dados e evitar o sobreajuste aos dados de treinamento.\n",
    "\n",
    "3.5 O propósito de um conjunto de validação é avaliar diferentes configurações de hiperparâmetros e escolher aquela que resulta no melhor desempenho no conjunto de validação. Isso é importante para evitar o ajuste excessivo aos dados de treinamento e garantir que o modelo generalize bem para novos dados.\n",
    "\n",
    "3.6 Ajustar hiperparâmetros usando o conjunto de teste pode levar ao ajuste excessivo aos dados de teste e resultar em um modelo que não generaliza bem para novos dados. Isso é conhecido como vazamento de informações (leakage) e pode ser evitado usando um conjunto de validação separado para ajustar os hiperparâmetros."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
